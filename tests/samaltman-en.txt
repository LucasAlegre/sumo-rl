welcome to the entrepreneurial
thought leader seminar at Stanford university
this is the Stanford seminar for aspiring entrepreneurs
ETL is brought to you by STVP
the Stanford entrepreneurship engineering center and basis
the business association of Stanford entrepreneurial students
i'm Ravi Balani
a lecturer in the management
science and engineering department
and the director of Alchemist
an accelerator for enterprise startups
and today i have the pleasure of welcoming sam
altman to etl
Sam is the co founder and ceo of open ai open is not a word
i would use to describe the seats in this class
and so i think by virtue of that
that everybody already plays knows open ai
but for those who don't open AI
is the research and deployment company behind chat GBT
Dolly and Sora
Sam's life is a pattern of breaking boundaries
and transcending what's possible both for himself
and for the world
he grew up in the Midwest in St Louis came to Stanford
took ETL as an undergrad
and we held on to Stanford for or Sam for two years
he studied computer science
and then after his sophomore year
he joined the inaugural class of y combinator
with a social mobile app
company called looped um that
then went on to go raise money from Sequoia
and others
he then dropped out of Stanford spent seven years on loop
which got acquired
and then he rejoined y combinator in an operational role
he became the president of y Combinator from 2014 to 2019
and then in 2015
he co founded open ai as a nonprofit research lab
with the mission to build general purpose
artificial intelligence that benefits all humanity
open AI has set
the record for the fastest growing app in history
with the launch of chatgbt
which grew
to a hundred million active users just two months after launch
sam was named one of times
hundred most influential people in the world
he was also named times ceo of the year in 2023
and he was also
most recently added to Forbes list of the world's billionaires
Sam lives with his husband in San Francisco
and splits his time between San Francisco and Napa
and he's also a vegetarian and so with that
please join me in welcoming
Sam altman to the stage
and in full disclosure that was a longer introduction than
sam probably would have liked brevity is the soul of wit
and so we'll try to make the questions more concise but this is
this is
this is also Sam's birth week it was his birthday on Monday
and i mentioned that
just because i think this is an auspicious moment
both in terms of time
you're 39 now
and also place
you're at Stanford in etl
that i would be remiss
if this wasn't sort of a moment of just some reflection
and i'm curious
if you reflect back on when you were half a life
younger when you were 19
in etl um if there
were three words to describe what your felt sense was like
as a Stanford undergrad what would those three words be
it's always hard questions
um
i was like you want three words only okay
you can go more sam you're the king of brevity
excited optimistic and curious
and what would be your three words now
i guess the same
which is terrific
so there's been a constant thread
even though the world has changed
and you know a lot has changed in the last 19 years
but that's gonna pale in comparison
what's gonna happen in the next 19 yeah
and so i need to ask you for your advice
if you were a Stanford undergrad today
so if you had a freaky Friday moment tomorrow
you wake up and suddenly
you're 19 inside of i was Stanford undergrad knowing everything
you know what would you do what would you do
i'd be very happy
i would feel like
i was like coming of age at the luckiest time
like in several centuries probably
i think the degree to which the world is is gonna change
and the opportunity to impact that starting a company
doing ai research
any number of things is like quite remarkable
i think this is probably the best time to start
yeah i think i would say this
i think this is probably the best time to start
a company since the internet at least
and maybe kind of like in the history
of technology
i think what you can do with ai
is like gonna just get more remarkable every year
and the greatest companies get created at times like this
the most impactful new products get built at times like this
so i would feel incredibly lucky uh
and i would be determined to make the most of it
and i would go figure out
like where i wanted to contribute and do it and do
you have a bias on
where would you contribute
would you want to stay as a student
and if so would you major
in a certain major given the pace of change
probably i would not stay as a student
but only because like i didn't and i think it's like
reasonable to assume
people kind of are going to make the same decisions
they would make again
欢迎来到斯坦福大学创业思想领袖研讨会
这是斯坦福大学为有抱负的企业家举办的研讨会
ETL 由 STVP 为您带来
斯坦福创业工程中心和基础
斯坦福创业学生商业协会
我是 Ravi Balani
管理科学与工程系讲师
以及企业初创企业加速器 Alchemist 的主管
今天我很高兴欢迎 sam
altman 来到 etl
Sam 是 open ai 的联合创始人兼首席执行官
open 不是我用来描述这堂课座位的词
所以我认为凭借这一点
每个人都已经知道 open ai
但对于那些不了解 open AI 的人来说
是 chat GBT 背后的研究和部署公司
Dolly 和 Sora
Sam 的生活是一种打破界限的模式
超越了自己和世界的可能性
他在中西部圣路易斯长大
来到斯坦福大学
以 ETL 为本科生
我们在斯坦福大学坚持了两年
他学习了计算机科学
然后在大二之后
他加入了 y combinator 的首届班级
并创办了一家名为 looped um 的社交移动应用
然后继续从 Sequoia 和其他公司筹集资金
然后他从斯坦福大学辍学，在 loop 上呆了七年
后来被收购了
然后他重新加入 y combinator 担任运营职务
他从 2014 年到 2019 年担任 y combinator 的总裁
然后在 2015 年
他与他人共同创立了 open ai，这是一个非营利性研究实验室
其使命是构建造福全人类的通用人工智能
open ai 创造了
历史上增长最快的应用程序记录
chatgbt 的推出
在推出两个月后就增长到一亿活跃用户
sam 被时代评为
全球百大最具影响力人物之一
他还被时代评为 2023 年度首席执行官
他最近还被福布斯列入全球亿万富翁
Sam 和他的丈夫住在旧金山
他经常往返于旧金山和纳帕
他还是素食主义者，所以
请和我一起欢迎
Sam altman 上台
坦白说，这是一个比
Sam 可能希望的更长的介绍，简洁是智慧的灵魂
所以我们会尽量让问题更简洁，但这是
这是
这也是 Sam 的出生周，星期一是他的生日
我提到这一点
只是因为我认为这是一个吉祥的时刻
无论是从时间上来说
你现在 39 岁
也是从地点上来说
你在斯坦福大学
如果这不是一个反思的时刻，那我就太疏忽了
我很好奇
如果你回想一下你年轻了一半的时候
当你 19 岁的时候
如果有三个词来描述你作为斯坦福本科生的感受
那会是什么
这总是很难问题
嗯
我当时想你只想说三个词，好吗
你可以说得更多，山姆，你是简洁之王
兴奋、乐观和好奇
你现在想说的三个词是什么
我想是一样的
这太棒了
所以一直有一个不变的主题
即使世界已经改变
你知道在过去的 19 年里发生了很多变化
但相比之下，这些都会黯然失色
未来 19 年会发生什么，是的
所以我需要向你征求建议
如果你今天是斯坦福大学的本科生
所以如果你明天有一个怪异的星期五时刻
你醒来，突然
你内心 19 岁，我是斯坦福大学的本科生，知道一切
你知道你会做什么你会做什么
我会很高兴
我会觉得
我就像在最幸运的时候成年一样
就像几个世纪以来可能一样
我认为世界将发生改变的程度
以及影响它的机会创办一家公司
从事人工智能研究
任何事情都非常了不起
我认为这可能是开始的最佳时机
是的，我想我会这么说
我认为这可能是自互联网以来创办公司的最佳时机
也许有点像技术史上的
我认为你可以用人工智能做的事情
每年都会变得更加引人注目
最伟大的公司就是在这样的时刻诞生的
最具影响力的新产品就是在这样的时刻诞生的
所以我会感到非常幸运
我会下定决心充分利用它
我会去弄清楚
我想在哪里做出贡献并去做
你对
你会在哪里做出贡献有偏见吗
你想继续当学生吗
如果是这样的话，考虑到变化的速度，你会主修某个专业吗
可能我不会继续当学生
但只是因为我没有，我认为
可以合理地假设
人们会做出同样的决定
他们会再次做出同样的决定

i think Stan as a student is a perfectly good thing to do
i just i it would probably not be what i would have picked no
and this is you
this is you so you have the freaky Friday moment
it's you you're reborn and as a 19 year old yeah
and would you yeah
what i think i would again
like i think this is not a surprise
because people kind of are going to do what they're going to do
i think i would go work on ai research
and where might you do that Sam
i think i mean obviously i have a bias towards open access
but i think anywhere
i could like do meaningful ai research
i would be like very thrilled about
so you'd be agnostic if that's academia or private industry
i say this with sadness
i think i would pick industry realistically
i think it's i think to you kind of
need to be at a place with so much compute okay
and if you did join on the research side
would you join
so we had kazor here
last week who was a big advocate of not being a founder
but actually joining an existing company to learn
learn the chops
for the for the students
that are wrestling with should i start a company
now at 19 or 20
or should i go join another entrepreneurial either research lab
or venture what advice
would you give them
well
since he gave the case to join a company
i'll give the other one
which is i think you learn a lot just starting a company
and if that's something you want to do at some point
there's this thing
Paul Graham says but i think it's like very deeply true
there's no pre startup
like there is pre med
you kind of
just learn how to run a startup by running a startup
and if that's what you're pretty
sure you want to do you may as well jump in and do it
and so let's say so if somebody wants to start a company
they want to be an ai um
what do you think
are the biggest
near term challenges that you're seeing in ai
that are the ripest for a start up
and just to scope that what i mean by that are what are
the holes that you think
are the top priority needs for open ai
that open ai will not solve in the next three years yet
so
i think
this is like a very reasonable question to ask in some sense
but i think
it's i'm not going to answer it because i think you should never
take this kind of advice about what started to start
ever from anyone um
i think by the time
there's something that is like the kind of thing
that's obvious enough that me or somebody else will sit up here
and say it it's probably like not that great of a startup idea
and i totally understand the impulse and i remember
when i was just like asking people like what startup
should i start
but i think like one of the most important things
i believe about
having an impactful career is you have to chart your own course

if if the thing that you're thinking about
is something that someone else is gonna do anyway
or more likely something that a lot of people are gonna do
anyway um
you should be like somewhat skeptical of that
and i think a really good muscle to build is coming up with the
ideas that are not the obvious ones to say
so i don't know what the really important idea is that
i'm not thinking of right now
but i'm very sure someone in this room
knows what that answer is
and i think
learning to trust yourself and come up with your own ideas
and do the very like non consensus things like
when we started open
ai that was an extremely non consensus thing to do and now
it's like the very obvious thing to do now
i only have the obvious ideas
because i'm just like stuck in this one frame
but i'm sure you all have the other ones
so can i ask it another way
and i don't know if this is fair or not
but what questions then are you wrestling with that
no one else is talking about
how to build really big computers
i mean i think other people are talking about that
but we're probably like
looking at it
through a lens that no one else is quite imagining yet
i mean we're definitely wrestling with how
we when we make not just like grade school or middle school
or level intelligence
but like PhD level intelligence
and beyond the best way to put that into a product
the best way to have a positive impact with that on society
and people's lives we don't know the answer to that yet
so i think that's like a pretty important thing to figure out
okay and can we continue on that thread
then of how to build really big computers
if that's really what's on
your mind can you share
i know there's been a lot of speculation
and probably a lot of hearsay too about the semiconductor
foundry endeavor that you are reportedly embarking on
can you share
what would make what's the vision
yeah would make this different than others that are out there
just foundries although that's part of it
it's like if you believe
which we increasingly do at this point that ai
infrastructure is gonna
be one of the most important inputs to the future
我认为斯坦作为一名学生是一件非常好的事情
我只是我可能不会选择不
这就是你
这就是你所以你有怪异的星期五时刻
是你重生了，作为一个 19 岁的人是的
你会是的
我认为我会再次
我想这并不奇怪
因为人们会做他们想做的事情
我想我会去研究人工智能
你会在哪里做 Sam
我想我的意思是显然我对开放获取有偏见
但我认为任何地方
我都可以做有意义的人工智能研究
我会非常兴奋
所以你会对学术界或私营企业持不可知论
我悲伤地说
我想我会现实地选择行业
我认为对你来说
需要在一个有如此多计算的地方好吗
如果你真的加入了研究方面
你会加入吗
所以上周我们有 kazor 在这里
他是大力提倡不要成为创始人，而是加入一家现有的公司来学习，学习技能，对于那些正在纠结于现在 19 岁还是 20 岁应该创办一家公司，还是应该加入另一家创业公司，研究实验室或风险投资的学生，你会给他们什么建议呢？既然他提出了加入一家公司的案例，我会给他们另一个建议，那就是我认为你只要创办一家公司就能学到很多东西，如果这是你在某个时候想做的事情，保罗·格雷厄姆说，但我认为这是非常正确的，没有预创业，就像有医学预科一样，你只是通过经营一家初创公司来学习如何经营一家初创公司，如果你很确定你想做这件事，你也可以直接去做，所以假设有人想创办一家公司，他们想成为一名人工智能，你认为人工智能领域面临的最大短期挑战是什么？最适合创业的时机
我只是想说一下，你认为开放人工智能的首要需求是什么，而开放人工智能在未来三年内还无法解决
所以
我认为
从某种意义上说，这是一个非常合理的问题
但我认为
我不会回答它，因为我认为你永远不应该
接受这种关于从何开始的建议
嗯
我认为到时候
有某种事情很明显，我或其他人会坐在这里
说它可能不是一个好的创业想法
我完全理解这种冲动，我记得
当我问人们我应该开始什么创业时
但我认为最重要的事情之一是
我相信拥有有影响力的职业生涯
你必须规划自己的路线
如果你正在考虑的事情
是别人无论如何都会做的事情
或者更可能是很多人会做的事情无论如何，嗯，你应该对此持怀疑态度，我认为真正要锻炼的就是想出那些不是显而易见的想法，所以我不知道真正重要的想法是什么，我现在没有想到，但我很确定这个房间里的某个人知道答案是什么，我认为学会相信自己，想出自己的想法，做一些非常不合时宜的事情，比如当我们开始开放人工智能时，这是一个非常不合时宜的事情，现在，这就像现在非常明显的事情，我只有明显的想法，因为我就像被困在这个框架里，但我相信你们都有其他的想法，所以我能换个方式问吗，​​我不知道这是否公平，但你在努力解决什么问题，没有人谈论如何建造真正的大型计算机，我的意思是，我认为其他人正在谈论这个问题，但我们可能只是通过一个镜头来看待它，另一个人还在想办法
我的意思是，我们肯定在努力解决如何
当我们制造的不仅仅是小学或中学水平的智能
而是博士水平的智能
以及将其融入产品的最佳方式
如何对社会和人们的生活产生积极影响的最佳方式
我们还不知道答案
所以我认为这是一件非常重要的事情
好的，我们可以继续讨论这个话题吗
然后是如何制造真正的大型计算机
如果这真的是你的想法，你能分享一下吗
我知道有很多猜测
可能也有很多关于你正在着手的半导体
代工厂努力的传闻
你能分享一下
什么会让你的愿景是什么
是的，会让这个与其他代工厂不同，尽管这是其中的一部分
就像如果你相信
我们现在越来越多地这样做，人工智能
基础设施将成为未来最重要的投入之一

this commodity
that everybody's gonna want
and that is energy data centers
chips chip design
new kinds of networks it's how we look at that entire ecosystem
and how we make a lot more of that
and i don't think
it'll work to just look at one piece or another
but we got to do the whole thing okay
so there's multiple big problems yeah
i think like just this is the arc of human technological history
as we build bigger and more complex systems
and is it gross
so you know in terms of just like the compute cost correct me
if i'm wrong but chat gbt3 was i've heard
it was a hundred million dollars to do the model
and it was a hundred one hundred seventy
five billion parameters
gbt4 was cost 400 million dollars with 10x the parameters
it was almost 4x the cost
but 10x the parameters correct me adjust me you know it
i do i do know it but i won't oh
you can you're invited to this is Stanford Sam okay
but even if you don't want to correct the actual numbers
if that's directionally correct
does the cost do you think keep growing with each subsequent
yes and does it keep growing
multiplicatively
uh probably i mean and the question then becomes how do we
how do you capitalize that
well
look i kind of think that
giving people really capable tools and letting them figure out
how they're going to use this
to build the future is a super good thing to do
and is super valuable
and i am super willing to bet on the ingenuity of you
all and everybody else in the world to figure out
what to do about this
so there is probably some more business minded
person than me at open ai
somewhere that is worried about how much we're spending um
but i kind of don't okay
so that doesn't cross it so you know
Openai's phenomenal chatgpt's phenomenal
everything else all the other models are phenomenal
it burned you've burned 520 million dollars of cash
last year that doesn't concern you in terms of
thinking about the economic model of how do you actually
where's gonna be the monetization source
well first of all that's nice of you to say
but chatbot is not phenomenal like
chatbot is like mildly embarrassing at best
gpt4 is the dumbest model
any of you will ever ever have to use again by a lot
but you know it's like important to ship early and often
and we believe in iterative deployment
like if we go build agi in a basement
and then you know the world is like kind of
blissfully walking blindfolded
along i don't think that's like the only thing that makes us
like very good neighbors
so i think it's important
given what we believe is going to happen to express our view
about what we believe is going to happen
but more than that the way to do
it is to put the product in people's hands and
let society co evolve with the technology
let society tell us what it collectively
and people individually want from the technology
how to productize this
in a way that's going to be useful
where the model works really well
where it doesn't work really well
give our leaders and institutions time to react
give people time to figure out
how to integrate this into their lives to learn
how to use the tool
sure some of you all like cheat on your homework with it
but some of you all probably do like very amazing
wonderful things with it too
and as each generation goes on i think that will expand and
and that means that we ship imperfect products
but we have a very tight feedback
loop and we learn and we get better
and it does kind of suck to ship
a product that you're embarrassed about
but it's much better than the alternative
and in this case in particular
where i think we really owe it to society to deploy iteratively
one thing we've learned is that ai
and surprise don't go well together
people don't want to be surprised
people want a gradual rollout
and the ability to influence these systems
that's how we're going to do it
and there may be
there could totally be things in the future that would change
where we'd think iterative deployment
isn't such a good strategy but
it does feel like the current best approach that we have
and i think we've gained a lot from doing this and you know
hopefully the larger world has gained something too whether
we burn 500 million a year
or 5 billion or 50 billion a year i don't care i genuinely
don't as long as we can i think stay on a trajectory
where eventually
we create way more value for society than that
and as long as we can figure out a way to pay the bills
like we're making agi
it's gonna be expensive it's totally worth it and so and so do
you have a vision in 2030 of what
if i say you crushed it
sam it's 2030 you crushed it
what does the world look like to you
这种商品
每个人都想要
那就是能源数据中心
芯片设计
新型网络
这是我们看待整个生态系统的方式
以及我们如何制造更多这样的产品
我不认为
只看一个部分或另一个部分是行不通的
但我们必须做整个事情，好吗
所以有多个大问题，是的
我认为这就是人类技术历史的弧线
随着我们建立更大更复杂的系统
这很恶心吗
所以你知道，就计算成本而言，纠正我
如果我错了，但聊天 gbt3 是我听说的
做这个模型花了一亿美元
而且有一百一千七百五十亿个参数
gbt4 花费了 4 亿美元，参数是 10 倍
几乎是成本的 4 倍
但参数是 10 倍纠正我调整我你知道的
我知道我知道但我不会哦
你可以你被邀请参加这是斯坦福山姆好吗
但即使你不想纠正实际数字
如果方向正确的话
你认为成本是否会随着后续的每次增长而不断增长
是的，它会不断增长吗
嗯，我的意思是，那么问题就变成了我们如何
如何利用它
嗯
我有点认为
为人们提供真正有能力的工具，让他们弄清楚
他们将如何使用它
来构建未来是一件非常好的事情
而且非常有价值
我非常愿意打赌你们所有人和世界上其他人的聪明才智来弄清楚
该怎么做
所以在 Open AI 的某个地方，可能有一些比我更有商业头脑的人
担心我们花了多少钱
嗯
但我有点不同意
所以这并没有越过它，所以你知道
Openai 的非凡的 chatgpt 是非凡的
其他一切，所有其他模型都是非凡的
它烧掉了你去年烧掉了 5.2 亿美元的现金
这与你无关
考虑到经济模型，你实际上如何
货币化来源在哪里
首先，你说得好
但聊天机器人并不惊人，
聊天机器人充其量只是有点尴尬
GPT4 是最愚蠢的模型
你们中的任何人都将不得不再次使用很多
但你知道，尽早和经常发货很重要
我们相信迭代部署
比如如果我们在地下室建造 agi
然后你知道世界就像
蒙着眼睛幸福地走着
我不认为这是让我们成为非常好的邻居的唯一原因
所以我认为重要的是
考虑到我们相信会发生什么，表达我们对我们相信会发生什么的看法
但更重要的是，这样做的方法是
把产品交到人们手中，
让社会与技术共同发展
让社会告诉我们它集体
和人们个人想要从技术中得到什么
如何以一种方式将其产品化有用
模型运行良好的地方
模型运行不佳的地方
给我们的领导者和机构时间做出反应
给人们时间弄清楚
如何将其融入他们的生活以学习
如何使用该工具
当然你们中的一些人喜欢用它作弊
但你们中的一些人可能也喜欢用它做非常了不起的事情
随着每一代人的成长，我认为这种情况会扩大，这意味着我们交付的产品不完美
但我们有一个非常紧密的反馈
循环，我们会学习并变得更好
交付让你感到尴尬的产品确实有点糟糕
但它比其他选择要好得多
特别是在这种情况下
我认为我们真的应该对社会进行迭代部署
我们学到的一件事是人工智能
和惊喜并不相配
人们不想感到惊讶
人们想要逐步推出
以及影响这些系统的能力
这就是我们要做的事情
而且可能会有
完全有可能未来会发生改变
我们认为迭代部署
不是一个好的策略，但
感觉这是我们目前最好的方法
我认为我们从中获益良多，你知道
希望更大的世界也能有所收获
无论我们每年烧掉 5 亿美元
还是 50 亿美元或 500 亿美元，我不在乎，我真的不在乎
只要我们能保持轨迹
最终
我们为社会创造的价值要比这多得多
只要我们能想出办法来支付账单
就像我们在制造人工智能
它会很贵，但完全值得，所以
你对 2030 年有什么愿景
如果我说你粉碎了它
山姆，那是 2030 年，你粉碎了它
你觉得世界是什么样子的
um
you know maybe in
some very important ways
not that different like we will be back here
there will be like a new set of students
we'll be talking about how startups are really important
technology is really cool
we'll have this new great tool in the world it'll feel
it would feel amazing
if we got to teleport forward six years today
and have this thing that was like smarter than humans
in many subjects
and could do these complicated tasks for us and
you know like
we could have these like complicated program written
or this research done or this business started
and yet like the sun
keeps rising the like people keep having their human dramas
life goes on so sort of like super different in some sense
that we now have like abundant intelligence at our fingertips
and then in some other sense like not different at all
and you mentioned artificial general intelligence AGI
artificial general intelligence and in a previous interview
you defined that as software that could mimic the median
competence of a
or the competence of a median human for tasks yeah
can you give me
is our time
if you had to do a best guess of when you think or arrange
you know i feel like that's gonna happen
i think we need a more precise definition of agi
for the timing question
because at this point even with like the definition
you just gave
which is a reasonable one
there's still that's your i'm parroting back what you said
in an interview well
that's good because i'm going to criticize myself okay
it's it's it's too loose of a definition
there's too much room for misinterpretation in there
to i think be really useful
or get at what people really want like
i kind of think what people want to know when they say like
what's the timeline to agi is like when is the world
gonna be super different when is the rate of change
gonna get super high when is the way
the economy works
gonna be really different like when does my life change
and that for a bunch of reasons may be very different than
we think like
i can totally imagine a world
where we build PhD level intelligence in any area
and you know we can make researchers way more productive
maybe we can even do some autonomous research
and in some sense like
that sounds like it should change the world a lot
and i can imagine that we do that
and then we can detect no change in global gdp growth
for like years afterwards
something like that
which is very strange to think about
and it was not my original intuition of how
this was all gonna go
so i don't know how to give a precise timeline of
when we get to the milestone people care about
but when we get to systems
that are way more capable than we have right now
one year and every year after
and that i think is the important point
so i've given up on trying to give the agi timeline
but i think every year for the next
many we have dramatically
more capable systems every year
i want to ask about the dangers of agi and gang
i know there's tons of questions for sam in a few moments
i'll be turning it up
so start thinking about your questions a big focus on Stanford
right now is ethics
and can we talk about you know
how you perceive the dangers of a gi
and specifically do you think the biggest danger from a gi
is gonna come from a cataclysmic event
which you know makes all the papers
or is it gonna be more subtle and pernicious
sort of like you know
like how everybody has add right now from you know
using right talk
is it are you more concerned about the subtle dangers
or the cataclysmic dangers um
or neither i'm more concerned about the subtle dangers
because i think we're more likely to overlook
those the cataclysmic dangers
a lot of people talk about and a lot of people think about
and i don't want to minimize
those i think they're really serious and a real thing
but i think we at least know to look out for that
and spend a lot of effort
um the example
you gave of everybody getting add from TikTok
or whatever i don't
think we knew to look out for
and that that's a really hard
the unknown unknowns are really hard
and so i'd worry more about those
although i worry about both
and are the unknown unknowns are there
any that you can name that
you're particularly worried about well
then i would kind of they be unknown unknown well
you can i
i am worried just about so even though i think in the short term
things change less than we think as with other major
technologies in the long term
i think they change more than we think
and i am worried about what rate
society can adapt to something so new and how long
it'll take us to figure out the new social contract versus
how long we get to do it
嗯

你知道也许在
一些非常重要的方面

没什么不同，比如我们会回到这里

会有一批新的学生

我们会谈论创业公司的重要性

技术真的很酷

我们将拥有这个世界上新的伟大工具，感觉

那会很棒

如果我们今天能够传送到六年后，拥有这个在许多学科上都比人类更聪明的东西

并且可以为我们完成这些复杂的任务，

你知道，我们可以编写这些复杂的程序

或者进行这项研究，或者开始这项业务

然而，就像太阳

不断升起，人们继续上演着他们的人间戏剧

生活继续，在某种意义上，这有点超级不同

我们现在拥有丰富的智能

然后在其他意义上，就像完全没有不同

你提到了人工智能 AGI

人工智能，在之前的采访中

你将其定义为可以模仿中等能力的软件

或者中等人类完成任务的能力，是的

你能给我

我们的时间吗

如果你必须对你认为或安排的时间做出最佳猜测
你知道我觉得那会发生
我认为我们需要对 agi 进行更精确的定义
对于时间问题
因为在这一点上，即使像你刚刚给出的定义一样
这是一个合理的定义
但那仍然是你在重复你在采访中所说的话
那很好，因为我要批评自己了，好吧
它的定义太宽泛了
那里有太多误解的空间
我认为它真的很有用
或者得到人们真正想要的东西，比如
我想人们在说 agi 的时间表时想知道什么
世界什么时候会变得非常不同
变化率什么时候会变得非常高
经济运作的方式什么时候会变得非常不同
比如我的生活什么时候会改变
出于很多原因，这可能与我们想象的非常不同
我完全可以想象一个世界
我们在任何领域建立博士级智能领域
而且你知道我们可以让研究人员更加高效
也许我们甚至可以做一些自主研究
在某种意义上
这听起来应该会改变世界很多
我可以想象我们这样做
然后我们可以发现全球 GDP 增长没有变化
在接下来的几年里
类似这样的事情
想想就很奇怪
这不是我最初对这一切将如何进行的直觉
所以我不知道如何给出一个精确的时间表
当我们达到人们关心的里程碑时
但是当我们获得比现在更强大的系统时
一年和之后的每一年
我认为这是重点
所以我已经放弃尝试给出 agi 时间表
但我认为接下来的每一年
我们每年都有显着更强大的系统
我想问一下 agi 和帮派的危险
我知道几分钟后有很多问题要问 Sam
我会调高音量
所以开始思考你的问题
现在的重点是斯坦福道德
我们可以谈谈你知道
你如何看待 gi 的危险
具体来说，你认为 gi 最大的危险
是来自灾难性事件
你知道这会让所有的报纸都报道出来
还是会更微妙和有害
有点像你知道的
就像现在每个人都有 add，你知道的
使用正确的谈话
是你更关心微妙的危险
还是灾难性的危险嗯
或者两者都不是我更关心微妙的危险
因为我认为我们更有可能忽视
那些灾难性的危险
很多人都在谈论，很多人都在思考
我不想最小化
那些我认为它们非常严重和真实的事情
但我认为我们至少知道要注意这一点
并花费大量精力
嗯你举的每个人都从 TikTok 获得 add 的例子
或者什么我不认为我们知道要注意
而且那真的很难
未知的未知数真的很难
所以我更担心这些
虽然我担心两者
还有未知的未知数
你能说出任何你特别担心的吗
那么我会觉得它们是未知的未知数
你可以吗
我担心的是，所以即使我认为在短期内
事情的变化比我们想象的要少，就像其他主要技术一样
从长远来看
我认为它们的变化比我们想象的要多
我担心的是
社会能以什么样的速度适应如此新的东西，以及
我们需要多长时间才能弄清楚新的社会契约，以及
我们需要多长时间才能做到这一点

i'm worried about that
i'm gonna i'm gonna open up
so i want to ask you a question about one of the key things
that we're now trying to inculcate into the curriculum
as things change
so rapidly is resilience mm that's really good and and you know
and the cornerstone of resilience is self awareness and so
and i'm wondering if you feel that you're pretty self
aware of your driving motivations
as you are embarking on this journey
so first of all
i think i believe
resilience can be taught
i believe
it has long been one of the most important life skills
and in the future
i think in the over the next
couple of decades
i think resilience and adaptability will be more important than
they've been in a very long time so uh
i think that's really great um on the self awareness question
i think i'm self aware
but i think like everybody thinks they're self aware
and whether i am
or not is sort of like hard to say from the inside
and can i ask
you sort of the questions that we ask in our intro classes on
self awareness sure
it's like the Peter drucker framework so what do you think
your greatest strengths are Sam
uh i
think i'm not great at many things
but i'm good at a lot of things
and i think breath has become an underrated thing in the world
everyone gets like hyper specialized
so if you're good at a lot of things
you can seek connections across them
i think you can then kind of come up with the ideas
that are different than everybody else has
or that sort of the experts in one area have
and what are your most dangerous weaknesses
most dangerous
that's an interesting framework for it
i think i have like a general bias to be too pro technology
just because i'm curious
and i want to see where it goes
and i believe that technology is on the whole a net good thing
but i think that is a worldview that has overall served me
and others well
and thus gotten like a
lot of positive reinforcement and is not always true
and when it's not been true
has been like pretty bad for a lot of people
and then Harvard psychologist David Mclelland
has this framework
that all leaders are driven by one of three primal needs
a need for affiliation
which is the need to be liked
a need for achievement
and a need for power if you had to rank list
those what would be yours
i think at various times in my career all of those
i think they're these like levels that people go through
at this point i feel driven by like
wanting to do something useful and interesting
but i think i definitely had like the money and the power
and the status phases okay
and then where were you when you most last felt
most like yourself
i always feel that way
and then one last question
and what are you most excited about with chat gbt 5
that's coming out that people don't
what are you most excited about with the release of chat gbt 5
that we're all gonna see
i don't know yet um
i mean this this sounds like a cop out answer
but i think the most important thing about gpt 5
or whatever we call that is just that it's gonna be smarter
and this sounds like a dodge
but i think
that's like among the most remarkable facts in human history
that we can just do something and
we can say right now
with a high degree of scientific certainty
GPT five is gonna be smarter than a lot smarter than GPT four
gpt six is gonna be a lot smarter than GPT five
and we are not near the top of this curve
and we kind of know what
know what to do
and this is not like it's going to get better in one area
this is not like
we're going to you know
it's not that it's always going to get better at this evaul
or this subject
or this modality
it's just going to be smarter in the general sense
and i think the gravity of that statement is still like
underrated okay
that's great sam guys
sam is really here for you he wants to answer your question
so we're going to open it up
hello um
thank you so much for joining us uh
i'm a junior here at Stanford
i sort of wanted to talk to you about responsible
deployment of agi
so as you guys
continually inch closer to that
how do you plan to deploy that responsibly at open ai uh
you know to prevent you know stifling human innovation
and continue to spur that
so i'm actually
not worried at all about stifling of human innovation
i really deeply believe that people will just surprise
us on the upside with better tools
i think all of history suggests that
if you give people more leverage
they do more amazing things
and that's kind of like we all get to benefit from that
that's just kind of great
i am though increasingly worried about how we're going to do
this all responsibly
我担心这个
我要敞开心扉
所以我想问你一个问题，关于我们现在试图灌输到课程中的一个关键问题
随着事物变化如此之快，韧性
嗯，这真的很好，你知道
韧性的基石是自我意识，所以
我想知道你是否觉得你对自己的驱动动机非常了解
当你踏上这段旅程时
所以首先
我认为
韧性是可以教授的
我相信
它长期以来一直是最重要的生活技能之一
在未来
我认为在接下来的几十年里
我认为韧性和适应性将比很长一段时间内更重要
所以呃
我认为这真的很棒
嗯关于自我意识的问题
我认为我有自我意识
但我认为每个人都认为他们有自我意识
而我是否有自我意识
从内心来说很难说
我可以吗问你一些我们在自我意识入门课上问的问题，当然，这就像彼得·德鲁克框架，所以你认为你最大的优势是什么，山姆，呃，我想我在很多事情上都不擅长，但我在很多事情上都很擅长，我认为呼吸已经成为世界上被低估的东西，每个人都变得非常专业，所以如果你擅长很多事情，你可以在它们之间寻找联系，我认为你可以想出一些想法，这些想法不同于其他人，或者某个领域的专家，你最危险的弱点是什么，最危险的，这是一个有趣的框架，我想我有一种普遍的偏见，过于支持技术，只是因为我很好奇，我想看看它会走向何方，我相信技术总体上是一件好事，但我认为这是一种总体上对我和其他人有益的世界观，因此得到了很多积极的强化，但并不总是正确的，当它没有被没错
对很多人来说，这很糟糕
然后哈佛心理学家 David Mclelland
有这个框架
所有领导者都受到三种原始需求之一的驱动
归属感的需求
也就是被喜欢的需求
成就感的需求
以及权力的需求
如果你必须对它们进行排名
这些会是你的吗
我认为在我职业生涯的不同时期，所有这些
我认为它们是人们经历的这些层次
在这一点上，我感觉受到想要做一些有用和有趣的事情的驱动
但我认为我肯定有钱和权力
和地位阶段，好吧
然后你最后一次感觉最像自己的时候在哪里
我一直有这种感觉
然后最后一个问题
你对 chat gbt 5 最兴奋的是什么
即将发布的但人们不知道
你对 chat gbt 5 的发布最兴奋的是什么
我们都会看到
我还不知道
我的意思是这听起来像一个逃避的答案
但我认为关于 GPT 5 最重要的一点
或者无论我们怎么称呼它，它都会变得更聪明
这听起来像是在躲避
但我认为
这是人类历史上最了不起的事实之一
我们可以做点什么
我们现在可以
以高度的科学确定性说
GPT 5 会比 GPT 4 聪明很多
GPT 6 会比 GPT 5 聪明很多
我们还没有接近这条曲线的顶端
我们知道什么
知道该做什么
这并不是说它会在某个领域变得更好
这并不是说
我们会知道
并不是说它总是会在这项评估
或这个主题
或这种模式
上变得更好
它只是在一般意义上变得更聪明
我认为这句话的重要性仍然被低估了
好吧
太好了，山姆，伙计们
山姆真的在这里为你服务，他想回答你的问题
所以我们要打开它上
你好，嗯
非常感谢你加入我们
我是斯坦福大学的大三学生
我想和你谈谈负责任的
部署 agi
所以随着你们
不断接近这一点
你打算如何在开放人工智能中负责任地部署它
你知道，为了防止扼杀人类创新
并继续刺激它
所以我实际上
一点也不担心扼杀人类创新
我真的深信人们会用更好的工具给我们带来惊喜
我认为所有的历史都表明
如果你给人们更多的杠杆
他们会做更多令人惊奇的事情
这有点像我们都从中受益
这真是太好了
但我越来越担心我们将如何负责任地做这一切

i think as the models get more capable
we have a higher and higher bar
we do a lot of things like red teaming and external audits
and i think those are all really good
but i think as the models get more capable
we'll have to deploy even more iteratively
have an even tighter feedback loop on
looking at how they're used and where they work
and where they don't work
and this world
that we used to do where we can release a major model update
every couple of years
we probably have to find ways to like
increase the granularity on that
and deploy more iteratively than we have in the past
and it's not super obvious to us yet how to do that
but i think that'll be key to responsible deployment
and also the way we kind of
have all of the stakeholders negotiate
what the rules of ai need to be
that's going to get more complex over time
too thank you next question over here
you mentioned before
that there's a growing need for larger and larger computers
and faster computers however
many parts of the world
don't have the infrastructure to build those data centers
or those large computers
how do you see global innovation being impacted by that
so
two parts to that one no matter where the computers are built
i think global and equitable
access to use the computers for training
as well as inference is super important
one of the things that's like very core to our mission is
that we make ChatGPT available for free to
as many people
as want to use it with the exception of certain countries
where we either can't or don't for a good reason
want to operate
how we think about making training compute
more available to the world
is are gonna become increasingly important
i i do think we get to a world
where we sort of think about it
as a human right to get access to a certain amount of compute
and we gotta figure out how to like
distribute that to people all around the world
there's a second thing
though which is
i think countries are going to increasingly
realize the importance of having their own ai infrastructure
and we want to figure out a way
and we're now spending a lot of time
traveling around the world to build them in the many countries
that will want to build these
and i hope
we can play some small role there in helping that happen tragic
thank you my question was what role
do you envision for ai in the future of like space
exploration or colonization
um
i think space is like not that hospitable for biological life
obviously and so if
we can send the robots that seems easier
哈哈哈哈
hey sam
so my question is for a lot of the founders in the room
and i'm going to give you the question
and then i'm going to explain why
i think it's complicated
so my question is about how you know an idea is non consensus
and the reason
i think it's complicated is because it's easy to overthink
i think today
even yourself says ai is the place to start a company
i think that's pretty consensus maybe rightfully
so it's an inflection point
i think it's hard to know if an idea is non consensus
depending on the group
that you're talking about the general
public has a different view of tech
from the tech community
and even tech elites have a different point of view
from the tech community
so
i was wondering how you verify that your idea is non consensus
enough to pursue um
i mean first of all what you really want is to be right
being contrarian and wrong is still is wrong
and if you predicted like 17 out of the last two recessions
you probably were contrarian for the two you got right
probably not even necessarily um
but you were wrong 15 other times and and
and so
i think it's easy to get too excited about being contrarian
and and again
like the most important thing to be right
and the group is usually right
but where the
most value is is when you are contrarian and right
and
and that doesn't always happen in like sort of a zero
or one kind of way
like everybody in the room
can agree that ai is the right place to start a company
and if one person in the room figures out
the right company to start
and then successfully executes on that
and everybody else thinks ah
that wasn't the best thing you could do that's what matters
so it's okay to kind of like go with conventional wisdom
when it's right
and then find the area
where you have some unique insight in terms of how to do
that i do think surrounding yourself
with the right peer group is really important
and finding original thinkers is important
我认为随着模型变得越来越强大，我们的标准越来越高，我们做了很多事情，比如红队和外部审计，我认为这些都很好，但我认为随着模型变得越来越强大，我们将不得不更加迭代地部署，有一个更紧密的反馈循环，以查看它们的使用方式、它们在哪里工作以及它们在哪里不起作用，而这个世界，我们过去所做的，我们可以每隔几年发布一个主要的模型更新，我们可能必须找到方法来增加粒度，并且比过去更加迭代地部署，目前我们还不清楚如何做到这一点，但我认为这将是负责任的部署的关键，也是我们让所有利益相关者协商人工智能规则的方式，随着时间的推移，这将变得更加复杂，谢谢你，下一个问题，你之前提到过，对越来越大的计算机和更快的计算机的需求越来越大，然而，许多部分世界
没有基础设施来建立这些数据中心
或大型计算机
您如何看待全球创新受到的影响
所以
无论计算机在哪里建造，这都分为两个部分
我认为全球和公平地使用计算机进行训练
以及推理非常重要
我们的使命的核心之一是
我们免费向尽可能多的人提供 ChatGPT，除了某些国家
我们不能或出于正当理由不想运营
我们如何考虑让训练计算
对世界更加可用
将变得越来越重要
我确实认为我们会进入一个世界
我们认为获得一定数量的计算是一项人权
我们必须弄清楚如何将其分发给世界各地的人们
但还有第二件事
我认为各国将越来越意识到拥有自己的人工智能基础设施的重要性
我们想找到一种方法
和我们现在花了很多时间
去世界各地建造它们，在许多想要建造这些的国家
我希望
我们可以在其中发挥一些小作用，帮助实现这一目标
谢谢我的问题是，你认为人工智能在未来的太空探索或殖民中扮演什么角色
嗯
我认为太空显然不适合生物生存
所以如果我们可以发送机器人，这似乎更容易
哈哈哈哈
嘿，山姆
所以我的问题是针对房间里的许多创始人
我会给你这个问题
然后我会解释为什么
我认为这很复杂
所以我的问题是关于你如何知道一个想法是非共识的
而原因
我认为这很复杂是因为很容易想太多
我认为今天
甚至你自己都说人工智能是创办公司的地方
我认为这是相当一致的，也许是正确的
所以这是一个转折点
我认为很难知道一个想法是否是非共识共识
取决于你谈论的群体
普通大众对科技的看法与科技界不同
甚至科技精英也有不同的观点
所以
我想知道你如何验证你的想法是否足够非共识
可以追求
我的意思是首先你真正想要的是正确的
逆势而行，错误仍然是错误的
如果你预测了过去两次经济衰退中的 17 次
你可能在两次衰退中都是逆势而行
你可能是正确的
但你在其他 15 次中是错误的
所以
我认为逆势而行很容易让人兴奋不已
而且
最重要的是要正确
群体通常是对的
但最有价值的是当你逆势而行并且正确的时候
而且
这并不总是以某种方式发生
就像房间里的每个人
都可以同意人工智能是创办公司的正确地方
如果房间里有一个人认为找到合适的公司
然后成功执行
然后其他人都认为
这不是你能做的最好的事情，这才是最重要的
所以，当传统智慧是正确的时候，遵循它
然后找到一个领域
你对如何做有独特的见解
我认为让自己周围
有合适的同龄人群体真的很重要
找到原创思想家也很重要

but there is part of this where you kind of have to do it solo
or at least part of it solo
or with a few other people who are like you know
gonna be your co founders or whatever
and i think by the time
you're too far in the like how can i find the right peer group
you're somehow in the wrong framework
already so like learning to trust yourself
and your own intuition
and your own thought process
which gets much easier over time
no one no matter what they say
they say i think is like truly great at this
when they're just starting out yeah
because like you kind of just haven't built
the muscle and like all of your social pressure
and all of like the evolutionary pressure that
produced you was against that
so it's something that like you get better at over time
and don't hold yourself to too high of a standard
too early on it
hi Sam i'm curious to know what your predictions are
for how energy demand will change in the coming decades
and how we achieve a future
where renewable energy sources are one cent
per kilowatt hour i mean it will go up for sure well
not for sure
you can come up with all these weird ways in which like
we all the depressing futures where it doesn't go up
i would like it to go up a lot
i hope that we hold ourselves to a high enough standard
where it does go up
i forget exactly
what the kind of world's electrical generating capacity
is right now
but let's say it's like three thousand four thousand gigawatts
something like that even
if we add another hundred gigawatts for ai
it doesn't materially change it that much
but it changes at some
and if we start at a thousand gigawatts for ai
someday that's a material change
but there are a lot of other things that we want to do
and energy does seem to correlate
quite a lot with quality of life we can deliver for people
my guess is that fusion eventually dominates
electrical generation on earth i think it
should be the cheapest most abundant
most reliable densest source
i could could be wrong on that
and it could be solar plus storage
and you know my guess most likely is it's gonna be 80 20
one way or the other
and there'll be some cases
where one of those is better than the other
but those kind of seem like the two bets for
like really global scale
1 cent per kilowatt hour energy
hi sam
i have a question it's about open guide
drive what happened last year
so what's the lesson you learn
because you talk about resilience
so what's the lesson you learn from left that company
and now coming back
and what made you coming back
because Microsoft also gave you an offer like can you share
more i mean the best lesson i learned was that
we had
an incredible team that totally could have run the company
without me and did for a couple of days and
you never and also that the team was super resilient
like we knew that some crazy things
and probably more crazy things will happen to us between here
and agi
um as different parts of the world
have stronger and stronger emotional reactions
and the stakes keep ratcheting it up and you know
i thought that the team would do well under a lot of pressure
but you never really know until you get to run the experiment
and we got to run the experiment
and i learned that the team was super resilient
and like ready to kind of run the company in terms of
why i came back
you know i originally when the so it was like the next morning
the board called me
and i was like what do you think about coming back
and i was like no i'm mad and
and then i thought about it
and i realized just like how much i loved open ai
how much i loved the people
the culture we had built the mission
and i kind of like
wanted to finish it all together you emotionally
i just want to this is obviously
a really sensitive one of the one of oh
it's not but was i imagine that was much okay
well then can we talk about the structure about it
because this Russian doll structure of the open ai
where you have the nonprofit owning the for profit
you know when we're trying to teach principal dragnon
we got here we got to the structure gradually
it's not what i would go back and pick
if we could do it all over again
but we didn't think
we were going to have a product when we started
we were just going to be like a ai
research lab wasn't even clear
we had no idea about a language
model or an api or ChatGPT
so if if you're going to start a company
you gotta have like some theory that
you're going to sell a product someday
and we didn't think we were going to we didn't realize
we were going to need so much money for compute
we didn't realize
we were going to like have this nice business
但其中有一部分你必须独自完成
或者至少部分是独自完成
或者和几个其他人一起完成，你知道
他们会成为你的联合创始人或其他什么人
我认为到那时
你走得太远了，比如我如何找到合适的同龄人
你已经不知何故处于错误的框架中
所以学会相信自己
和你自己的直觉
和你自己的思维过程
随着时间的推移，这会变得容易得多
无论他们说什么
没有人说我认为他们刚开始时真的很擅长这个
因为你还没有锻炼出肌肉，你所有的社会压力
以及所有产生你的进化压力
都与此相反
所以这是你会随着时间的推移而变得更好的事情
不要太早地对自己要求太高
嗨，山姆，我很好奇你对未来几十年能源需求将如何变化的预测是什么
以及我们如何实现可再生能源成为其中之一的未来美分
每千瓦时，我的意思是它肯定会上涨
嗯
不确定
你可以想出所有这些奇怪的方法，比如
我们都对它不上涨的未来感到沮丧
我希望它能涨很多
我希望我们能保持足够高的标准
它确实会上涨
我忘了现在世界发电能力到底是什么样的
但假设它是三千四千千兆瓦
类似的东西
即使我们为人工智能再增加一百千兆瓦
它也不会发生太大的改变
但它会有所改变
如果我们从一千千兆瓦开始
总有一天这是一个实质性的变化
但我们还有很多其他的事情要做
能源似乎与我们能为人们提供的生活质量有很大关系
我猜核聚变最终会主导地球上的发电
我认为它
应该是最便宜、最丰富、最可靠、最密集的能源
我可能错了那
而且它可能是太阳能加储能
你知道我猜最有可能是 80 20
不管怎样
而且有些情况下
其中一个比另一个更好
但这似乎是两个赌注
就像真正全球规模
每千瓦时 1 美分的能源
嗨，山姆
我有一个问题是关于开放指南
去年发生了什么
所以你学到了什么教训
因为你谈到了韧性
所以你从离开那家公司
现在回来
学到了什么教训
是什么让你回来的
因为微软也给了你一个报价，比如你能分享更多吗
我的意思是我学到的最好的一课是
我们有一支令人难以置信的团队，完全可以在没有我的情况下经营公司
而且做了几天，
你从来没有，而且团队非常有韧性
就像我们知道一些疯狂的事情
可能更多疯狂的事情会发生在我们身上
从这里到 agium
因为世界不同地区有越来越强烈的情绪反应
和赌注继续加大力度，你知道
我认为团队在很大的压力下会做得很好
但你永远不知道，直到你开始进行实验
我们开始进行实验
我了解到团队非常有韧性
并且准备好经营公司
为什么我回来
你知道我最初是什么时候，所以就像第二天早上一样
董事会打电话给我
我问你觉得回来怎么样
我说不，我很生气
然后我想了想
我意识到我有多爱开放人工智能
我有多爱这些人
我们建立的文化
我有点喜欢
想一起完成这一切
我只是想这显然是一个非常敏感的一个
哦
不是，但我想那很好
那么我们可以谈谈它的结构吗
因为这个开放人工智能的俄罗斯套娃结构
你让非营利组织拥有营利性组织
你知道当我们试图教导校长时dragnon
我们到了这里，我们逐渐形成了结构
这不是我会回去选择的
如果我们可以重新来过
但我们没想到
我们刚开始的时候会有一个产品
我们只是想成为一个人工智能
研究实验室甚至不清楚
我们对语言
模型或 api 或 ChatGPT 一无所知
所以如果你要创办一家公司
你必须有一些理论
你有一天会卖出一种产品
我们没有想到我们会这样做，我们没有意识到
我们需要这么多钱来计算
我们没有意识到
我们会有这么好的生意

so what was your intention when you started it
we just wanted to like push ai research forward
we thought that and i know this gets back to motivations
but that's the pure motivation
there's no motivation around making money or power
i cannot overstate how foreign of a concept like
i mean for you personally not for open ai
but you you weren't starting well
i had already made a lot of money
so it was not like a big i mean i like
i don't want to like claim some like moral purity here
it was just like that was the stage of my life
that's not a driver
driver okay
because there's this
so and the reason why i'm asking is just you know
when we're teaching about principle
driven entrepreneurship here
you can you can understand principles
inferred from organizational structures
when the United States was set up
the architecture of governance
is the constitution
it's got three branches of government
all these checks and balances
and you can infer certain principles that you know
there's a skepticism on centralizing power that you know
things will move slowly
it's hard to get things to change
but it'll be very very stable if you know
not to pair it Billy eilish but if you look at the open ai
structure and you think what was that made
for it's a you have a you're like
you're near a hundred billion
dollar valuation
and you've got a very very limited board
that's a nonprofit board
which is supposed to look after its fiduciary duties to the yes
that's not what we would have done if we knew now
then what we know now
but you don't get to like play life in reverse
and you have to just like adapt there's a mission
we really cared about
we thought we thought ai was gonna be really important
we thought we had an algorithm that learned we knew
it got better with scale
we didn't know how predictably it got better with scale
and we wanted to push on this
we thought this was like gonna be a very important thing
in human history
and we didn't get everything right
but we were right on the big stuff
and our mission hasn't changed
and we've adapted the structure as we go
and we'll adapt it more in the future um
but you know like you don't
like life is not a problem set you don't get to like solve
everything really nicely
all at once
it doesn't work quite like it works in the classroom
as you're doing it
and my advice is just like trust yourself to adapt as you go
it'll be a little bit messy but you can do it
and i just ask this
because of the significance of open ai you have a board
which is all supposed to be independent financially
so that they're making these decisions as a nonprofit
thinking about the stakeholder
their stakeholders that they are fiduciary of
isn't the shareholders it's humanity
everybody's independent
there's no financial incentive that anybody has
that's on the board
including yourself with open ai well
Greg was okay first of all
i think making money is a good thing
i think capitalism is a good thing
my co founders on the board have had financial interest
and i'd never once seen them
not take the gravity of the mission seriously um
but you know we've put a structure in place
that we think is a way to get incentives aligned
and i do believe incentives are superpowers
but i'm sure we'll evolve it more over time
and i think that's good not bad and with open ai
the new fund you don't get any carry in that
and you're not following on investments onto those countries
okay okay okay
thank you we can keep talking about this
no i know
i know
i know you want to go back to students i do too so we'll go
we'll keep going to the students
how do you expect that
agi will change geopolitics
and the balance of power in the world
phew
like maybe more than any other technology um
i don't i i think
about that so much
and i have such a hard time saying what
it's actually gonna do um i
or or maybe more accurately
i have such a hard time saying what it won't do you know
we're talking earlier about how it's like not gonna
maybe it won't change day to day life that much
but the balance of power in the world
it feels like it does change a lot
but i don't have a deep answer of exactly how
thanks so much i was wondering sorry
i was wondering in the deployment of like general intelligence
and also responsible ai
how much do you think
is it necessary that
ai systems are somehow capable of recognizing
their own insecurities
or like uncertainties
and actually communicating them to the outside world
那么你开始的时候的目的是什么
我们只是想推动人工智能研究向前发展
我们这么想，我知道这又回到了动机问题上
但这是纯粹的动机
没有赚钱或权力的动机
我不能夸大这个概念有多陌生，比如
我的意思是对你个人来说，不是对开放人工智能来说
但你起步不好
我已经赚了很多钱
所以这不是一个大问题，我的意思是我喜欢
我不想在这里宣称一些道德纯洁
这只是我人生的阶段
这不是驱动力
驱动力好吗
因为有这个
所以我问的原因只是你知道
当我们在这里教授原则驱动的创业精神时
你可以理解从组织结构推断出的原则
当美国成立时
治理架构
是宪法
它有三个政府部门
所有这些制衡
你可以推断出某些原则，你知道
人们对集中权力持怀疑态度知道
事情会慢慢发展
很难让事情发生变化
但如果你知道的话，它会非常非常稳定
不要将它与 Billy Eilish 配对，但如果你看看开放的人工智能
结构，你会想那是为它做的
你有一个你就像
你接近一千亿美元
估值
你有一个非常有限的董事会
这是一个非营利董事会
应该履行其受托责任
是的
如果我们现在知道，那不是我们会做的事情
那么我们现在知道的
但你不能像反向玩生活一样
你必须适应有一个使命
我们真的很关心
我们认为我们认为人工智能会非常重要
我们认为我们有一个学习的算法，我们知道
它会随着规模的扩大而变得更好
我们不知道它随着规模的扩大而变得更好有多可预测
我们想推动这一点
我们认为这将是人类历史上非常重要的事情
我们并没有把所有事情都做对
但我们是对的在大事上
我们的使命没有改变
我们在前进的过程中调整了结构
未来我们会更多地调整它
但你知道，就像你不
生活不是问题集，你无法解决
所有事情
一下子
它不像在课堂上那样工作
当你这样做的时候
我的建议是相信自己可以随时适应
它会有点混乱，但你可以做到
我只是问这个
因为开放人工智能的重要性，你有一个董事会
这一切都应该是财务独立的
所以他们以非营利组织的身份做出这些决定
考虑利益相关者
他们的利益相关者，他们是受托人
不是股东，而是人性
每个人都是独立的
没有任何人有经济激励
那是在董事会上
包括你自己和开放人工智能
格雷格首先没问题
我认为赚钱是一件好事
我认为资本主义是这是一件好事

董事会的联合创始人有经济利益

我从未见过他们

不认真对待任务的重要性

但你知道我们已经建立了一个结构

我们认为这是一种让激励机制保持一致的方式

我确实相信激励机制是超级大国

但我相信我们会随着时间的推移进一步发展它

我认为这是好事而不是坏事，有了开放人工智能

新基金，你不会获得任何收益

你不会跟进那些国家的投资

好的好的好的

谢谢，我们可以继续谈论这个

不，我知道

我知道

我知道你想回到学生那里，我也想，所以我们会继续

我们将继续讨论学生

你认为

人工智能会改变地缘政治

和世界的力量平衡

呼

可能比任何其他技术都更能改变

我不，我想

关于这个

我很难说它实际上会做什么

或者更准确地说

我有很难说它不会做什么，你知道吗
我们之前谈到过它不会
也许它不会对日常生活产生太大影响
但世界的力量平衡
感觉它确实发生了很大变化
但我没有一个深刻的答案，确切地说
非常感谢，我想知道抱歉
我想知道在部署通用智能
以及负责任的人工智能方面
你认为
人工智能系统是否有必要以某种方式识别
自己的不安全感
或不确定性
并将它们传达给外界

i always get nervous anthropomorphizing
ai too much
because i think it like can lead to a bunch of weird oversight
but if we say like how much can ai recognize its own flaws
i think that's very important to build and right now
and the ability to like recognize an error in reasoning
and have some sort of introspection
ability like that that seems to me
like really important to pursue
hey Sam
thank you for giving us some of your time today
and coming to speak from the outside
looking in
we all hear about the culture and togetherness of open ai
in addition to the intensity and speed of
which you guys work out
clearly seen from Cha gpt and all your breakthroughs and also
in when you were temporarily removed from the company
by the board and how all of your employees
tweeted Openair has nothing without its people
what would you say
is the reason behind
this is it the binding mission to achieve aji
or something even deeper what is pushing the culture every day
i think it is the shared mission
i mean i think people like like each other
and we feel like we're in the trenches together
doing this really hard thing but
i think it really is like deep
sense of purpose and loyalty to the mission
and when you can create that
i think it is like the strongest force for success at any start
at least that i've seen among startups
and you know we try to like select for that in people we hire
but even people who come in
not really believing that agi is going to be such a big deal
and that getting it right is so important
tend to believe it after the first
three months or whatever
and so
that's like that's a very powerful cultural force that we have
thanks
currently there are a lot of concerns about the misuse of ai
in the immediate term
with issues like global conflicts
and the election coming up what do you think can be done
by the industry
governments and honestly people like us in the immediate term
especially with
very strong open source models
one thing that i think is important
is not to pretend like this technology
or any other technology is all good
i believe that ai will be very net good
tremendously net good
but i think like with any other tool
it'll be misused like you can do great things with a hammer
and you can like kill people with a hammer
i don't think that absolves us
or you all or society from trying to mitigate the bad as much
as we can and maximize the good
but i do think it's important to realize that
with any sufficiently powerful tool
you do put power in the hands of tool users
or you make some decisions that constrain what people
and society can do
i think we have a voice in that
and you all have a voice in that
i think the governments
and our elected representatives in democratic processes
have the loudest voice in that
but we're not gonna get this perfectly right
like we society are not gonna get this perfectly right and
a tight feedback loop
i think is the best way to get it closest to right
and the way that that balance gets negotiated of safety versus
freedom and autonomy
i think it's like worth studying that
with previous technologies
and we'll do the best we can here
we society will do the best we can here
um gang actually
i've gotta cut it sorry i know um
i'm trying to be really sensitive to time
i know the the interest far
exceeds the time and the love for sam
um sam
i know it is your birthday i don't know if you can indulge us
cause i know there's a lot of love for you
so i wonder if you can all just sing happy birthday no
no no
please no
we want to make you very uncomfortable one more question
i'd much rather do one more question
this is less interesting to you thank you
we can you can do one more question
quickly
Davey dear sam
happy birthday to you 20 seconds of awkwardness
is there a burner question somebody's got a real burner
and we only have 30 seconds so make it short
um hi i wanted to ask
if the prospect of making something smarter than any human
could possibly be scares you
it of course does
我总是对过度拟人化感到紧张
因为我认为这会导致一系列奇怪的疏忽
但如果我们说人工智能能在多大程度上认识到自己的缺陷
我认为现在建立这一点非常重要
能够识别推理中的错误
并具有某种内省能力
在我看来，追求这种能力真的很重要
嘿，山姆
谢谢你今天抽出时间
从外面来看
我们都听说过开放人工智能的文化和团结
除了你们解决的强度和速度
从 Cha gpt 和你们所有的突破中可以清楚地看到
当你被董事会暂时从公司中除名时
以及你们所有的员工
发推文说 Openair 没有人就一无所有
你会说什么
背后的原因是什么
这是实现 aji 的约束性使命吗
或者更深层次的东西是什么每天推动着文化
我认为这是共同的使命
我的意思是我认为人们喜欢彼此其他
我们感觉我们在一起
做着一件非常困难的事情
但我认为这真的是一种深刻的
使命感和对使命的忠诚
当你能创造它的时候
我认为这就像任何开始取得成功的最强大力量
至少我在初创公司中看到过
你知道我们试图选择我们雇佣的人
但即使是那些进来的人
并不真的相信人工智能会成为一件大事
而且把它做好是如此重要
倾向于在头三个月或更长时间后相信它
所以
这就是我们拥有的非常强大的文化力量
谢谢
目前有很多人担心人工智能的滥用
在短期内
随着全球冲突等问题
以及即将到来的选举
你认为行业
政府和像我们这样的人
在短期内
特别是在非常强大的开源模型下
我认为重要的一件事
是不要假装这种技术
或任何其他技术都是好的
我相信人工智能将会带来非常好的净收益
非常非常好
但我认为就像任何其他工具一样
它会被滥用，就像你可以用锤子做伟大的事情
也可以用锤子杀人
我不认为这可以免除我们
或者你们所有人或社会尽可能地减轻坏事
并最大化好处
但我确实认为重要的是要意识到
对于任何足够强大的工具
你确实将权力交到了工具使用者的手中
或者你做出了一些限制人们
和社会可以做的事情的决定
我认为我们对此有发言权
你们都有发言权
我认为政府
和我们在民主进程中的民选代表
对此有最响亮的发言权
但我们不会把这件事做得完美无缺
就像我们社会不会把这件事做得完美无缺
我认为紧密的反馈循环
是让它最接近正确的最佳方式
以及在安全与自由和自治之间达成平衡的方式
我认为值得研究这一点
使用以前的技术
我们会做到我们能做到最好
我们社会会尽我们所能
嗯伙计们
我得删减一下，对不起，我知道嗯
我试图对时间非常敏感
我知道兴趣远远超过
对萨姆的时间和爱
嗯萨姆
我知道今天是你的生日，我不知道你是否能纵容我们
因为我知道有很多对你的爱
所以我想知道你们能不能都唱生日快乐歌
不
不不
请不要
我们想让你很不舒服
再问一个问题
我更愿意再问一个问题
这对你来说没那么有趣谢谢
我们可以，你可以再问一个问题
快点
戴维亲爱的萨姆
祝你生日快乐 20 秒的尴尬
有没有什么问题
有人有真正的问题
我们只有 30 秒，所以简短点
嗯嗨，我想问一下
制造比任何人类都聪明的东西的前景
是否可能让你害怕
当然会

and i think it would be like really weird and a bad sign
if it didn't scare me
humans have gotten dramatically
smarter and more capable over time you are dramatically
more capable than your great great grandparents
and there's almost no biological drift over
that period like sure you eat a little bit better
and you got better health care um
maybe you eat worse i don't know um
but that's not the main reason you're more capable
you are more capable
because the infrastructure of society is way smarter
and way more capable than
any human and through that it made you society
the people that came before you made you the internet
the iPhone
a huge amount of knowledge available at your fingertips
and you can do things that your predecessors would find
absolutely breathtaking
society is far smarter than you now society is an agi as far
as you can tell and the
and the way that that happened was not any individual's brain
but the space between
all of us that scaffolding that we build up
and contribute to brick by brick
step by step and then we use to go to far greater heights
for the people that come after us
things that are smarter than us
will contribute to that same scaffolding
you will have
your children will have tools available that you didn't
and that scaffolding
will have gotten built up to greater heights and
that's always a little bit scary but i think it's like more way
more good than bad
and people will do better things and solve more problems
and the people of the future
will be able to use these new tools
and the new scaffolding that these new tools contribute to
if you think about a world that has
ai making a bunch of scientific discovery
what happens to that scientific progress is
it just gets added to the scaffolding
and then your kids can do new things with it
or you in 10 years can do new things with it
but the way
it's going to feel to people
i think is not that there is this like much smarter entity
because we're much smarter in some sense than the great
great great grandparents are more capable at least
but that any individual person can just do more
on that we're going to end it so
let's give sam a round of applause
我认为这真的很奇怪，也是一个不好的迹象
如果它不让我害怕的话
人类随着时间的推移变得非常
聪明和有能力
你比你的曾曾祖父母更有能力
而且在那个时期几乎没有生物学漂移
比如你吃得更好一点
而且你得到了更好的医疗保健
也许你吃得更糟
我不知道
但这不是你更有能力的主要原因
你更有能力
因为社会的基础设施比任何人类都更聪明
而且更有能力
通过它，它创造了你
在你之前的人创造了你
互联网
iPhone
大量的知识触手可及
你可以做你的前辈会发现的事情
绝对令人叹为观止
社会比你聪明得多
现在社会是一种敏捷
据你所知
而发生这种情况的方式不是任何个人的大脑
而是我们之间
的空间
我们建立的脚手架
并为砖块做出贡献砖
一步一步，然后我们用它达到更高的高度
对于我们的后代来说
比我们更聪明的东西
将为同样的脚手架做出贡献
你将拥有
你的孩子将拥有你没有的工具
而那个脚手架
将被建造到更高的高度
这总是有点可怕，但我认为它的好处多于坏处
人们会做得更好，解决更多的问题
未来的人们
将能够使用这些新工具
以及这些新工具所贡献的新脚手架
如果你想想一个拥有人工智能进行大量科学发现的世界
科学进步会发生什么
它只是被添加到脚手架上
然后你的孩子可以用它做新的事情
或者你在 10 年后可以用它做新的事情
但人们会感觉到的方式
我认为不是有这种更聪明的实体
因为在某种意义上我们比伟大的
伟大的伟大的人更聪明祖父母至少更有能力
但任何个人都可以做得更多
我们将结束这一切，所以
让我们为山姆鼓掌