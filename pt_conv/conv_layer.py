import torch
import torch.nn as nn

# 输入是一个1x5x5的图像（1通道）
input_image = torch.tensor([[[[1, 2, 3, 4, 5],
                              [6, 7, 8, 9, 10],
                              [11, 12, 13, 14, 15],
                              [16, 17, 18, 19, 20],
                              [21, 22, 23, 24, 25]]]], dtype=torch.float32)

conv_layer = nn.Conv2d(1, 3, kernel_size=3)  # 1个输入通道，3个输出通道，卷积核大小为3

output = conv_layer(input_image)

print("input image shape: ", input_image.shape)
print("input:\n", input_image)
print(output.shape)
print("output:\n", output)

# 输入是一个1x7x7的图像（1通道）
input_image2 = torch.tensor([[[[1, 2, 3, 4, 5, 55, 56, ],
                                    [6, 7, 8, 9, 10, 65, 66],
                                    [11, 12, 13, 14, 15, 75, 76],
                                    [16, 17, 18, 19, 20, 85, 86],
                                    [21, 22, 23, 24, 25, 95, 96],
                                    [31, 32, 33, 34, 35, 97, 98]]]], dtype=torch.float32)

conv_layer2 = nn.Conv2d(1, 2, kernel_size=3)

output2 = conv_layer2(input_image2)

print("\ninput image shape: ", input_image2.shape)
print("input:\n", input_image2)
print("\noutput2.shape:", output2.shape)
print("output2:\n", output2)

"""
1个通道变成了3个通道。1个1通道高为5宽为5的图象，变成了1个3通道高为3宽为3的图象。
n = (W-F+2P)/S + 1
W:输入大小，F：卷积核大小，P：填充大小，S：步幅大小

input image shape:  torch.Size([1, 1, 5, 5])
input:
 tensor([[[[ 1.,  2.,  3.,  4.,  5.],
          [ 6.,  7.,  8.,  9., 10.],
          [11., 12., 13., 14., 15.],
          [16., 17., 18., 19., 20.],
          [21., 22., 23., 24., 25.]]]])
torch.Size([1, 3, 3, 3])
output:
 tensor([[[[ 0.1958, -0.4888, -1.1733],
          [-3.2269, -3.9114, -4.5960],
          [-6.6496, -7.3341, -8.0187]],

         [[-1.5260, -1.8645, -2.2030],
          [-3.2184, -3.5569, -3.8954],
          [-4.9109, -5.2493, -5.5878]],

         [[-1.0195, -1.5279, -2.0363],
          [-3.5614, -4.0698, -4.5782],
          [-6.1033, -6.6117, -7.1201]]]], grad_fn=<ConvolutionBackward0>)

input image shape:  torch.Size([1, 1, 6, 7])
input:
 tensor([[[[ 1.,  2.,  3.,  4.,  5., 55., 56.],
          [ 6.,  7.,  8.,  9., 10., 65., 66.],
          [11., 12., 13., 14., 15., 75., 76.],
          [16., 17., 18., 19., 20., 85., 86.],
          [21., 22., 23., 24., 25., 95., 96.],
          [31., 32., 33., 34., 35., 97., 98.]]]])

output2.shape: torch.Size([1, 2, 4, 5])
output2:
 tensor([[[[ -0.9454,  -1.8028,  -2.6602, -12.2039, -19.5939],
          [ -5.2325,  -6.0899,  -6.9474, -17.4958, -25.6548],
          [ -9.5196, -10.3771, -11.2345, -22.7877, -31.7157],
          [-12.0387, -12.8961, -13.7535, -28.7670, -40.9853]],

         [[  3.5430,   4.0328,   4.5226,  19.3351,  42.0753],
          [  5.9920,   6.4818,   6.9716,  22.9254,  47.8069],
          [  8.4409,   8.9307,   9.4205,  26.5156,  53.5386],
          [ 11.9861,  12.4759,  12.9657,  28.1335,  56.2301]]]],
       grad_fn=<ConvolutionBackward0>)

"""
